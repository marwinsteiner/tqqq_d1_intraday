{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest of the Intraday TQQQ Strategy\n",
    "The Strategy works as follows:\n",
    "1. Before market open, calculate the Average True Range (ATR) of TQQQ over the last 14 days. \n",
    "Use 7.5% of this number as your stop width.\n",
    "2. Wait for the first 5 minutes of price action. (09:30-09:34 EST). If the move from market open \n",
    "is positive, go long. If it's negative, go short.\n",
    "3. Place your stop at 7.5% ATR away from the 5-minute close.\n",
    "4. If your stop isn't hit, close the position at the end of the trading session (16:00 EST)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Setup, and and Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "from typing import Tuple, List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from polygon import RESTClient\n",
    "from config import settings\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set some pandas display options\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# Initialize Polygon client\n",
    "client = RESTClient(api_key=settings.POLYGON.API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cache_dir() -> Path:\n",
    "    \"\"\"Create and return the cache directory path\"\"\"\n",
    "    cache_dir = Path(\"data_cache\")\n",
    "    cache_dir.mkdir(exist_ok=True)\n",
    "    return cache_dir\n",
    "\n",
    "def get_cache_filename(symbol: str, timeframe: str, start_date: str, end_date: str) -> str:\n",
    "    \"\"\"Generate a consistent cache filename based on parameters\"\"\"\n",
    "    return f\"{symbol}_{timeframe}_{start_date}_{end_date}.csv\"\n",
    "\n",
    "def get_historical_data(symbol: str, start_date: str, end_date: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Get both 1-minute and 5-minute historical data from Polygon with caching\"\"\"\n",
    "    cache_dir = get_cache_dir()\n",
    "    \n",
    "    # Cache filenames for both timeframes\n",
    "    cache_1min = cache_dir / get_cache_filename(symbol, \"1min\", start_date, end_date)\n",
    "    cache_5min = cache_dir / get_cache_filename(symbol, \"5min\", start_date, end_date)\n",
    "    \n",
    "    if cache_1min.exists() and cache_5min.exists():\n",
    "        print(\"Loading cached data...\")\n",
    "        # Load with proper parsing of timezone-aware timestamps\n",
    "        df_1min = pd.read_csv(cache_1min, parse_dates=['timestamp'])\n",
    "        df_5min = pd.read_csv(cache_5min, parse_dates=['timestamp'])\n",
    "        \n",
    "        # Set index without timezone conversion\n",
    "        df_1min.set_index('timestamp', inplace=True)\n",
    "        df_5min.set_index('timestamp', inplace=True)\n",
    "        \n",
    "        return df_1min, df_5min\n",
    "    \n",
    "    print(\"Fetching historical data from Polygon...\")\n",
    "    \n",
    "    # Get 1-minute data for opening 5 minutes\n",
    "    aggs_1min = []\n",
    "    for a in tqdm(client.list_aggs(\n",
    "        ticker=symbol,\n",
    "        multiplier=1,\n",
    "        timespan=\"minute\",\n",
    "        from_=start_date,\n",
    "        to=end_date,\n",
    "        limit=50000\n",
    "    ), desc=\"1-min data\"):\n",
    "        dt = pd.Timestamp(a.timestamp, unit='ms', tz='UTC')\n",
    "        if dt.hour == 9 and 30 <= dt.minute <= 34:\n",
    "            aggs_1min.append({\n",
    "                'timestamp': a.timestamp,\n",
    "                'Open': a.open,\n",
    "                'High': a.high,\n",
    "                'Low': a.low,\n",
    "                'Close': a.close,\n",
    "                'Volume': a.volume\n",
    "            })\n",
    "    \n",
    "    # Get 5-minute data for the rest of the day\n",
    "    aggs_5min = []\n",
    "    for a in tqdm(client.list_aggs(\n",
    "        ticker=symbol,\n",
    "        multiplier=5,\n",
    "        timespan=\"minute\",\n",
    "        from_=start_date,\n",
    "        to=end_date,\n",
    "        limit=50000\n",
    "    ), desc=\"5-min data\"):\n",
    "        dt = pd.Timestamp(a.timestamp, unit='ms', tz='UTC')\n",
    "        if dt.hour > 9 or (dt.hour == 9 and dt.minute >= 35):\n",
    "            aggs_5min.append({\n",
    "                'timestamp': a.timestamp,\n",
    "                'Open': a.open,\n",
    "                'High': a.high,\n",
    "                'Low': a.low,\n",
    "                'Close': a.close,\n",
    "                'Volume': a.volume\n",
    "            })\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    df_1min = pd.DataFrame(aggs_1min)\n",
    "    df_5min = pd.DataFrame(aggs_5min)\n",
    "    \n",
    "    # Cache the data\n",
    "    df_1min.to_csv(cache_1min)\n",
    "    df_5min.to_csv(cache_5min)\n",
    "    \n",
    "    return df_1min, df_5min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_data(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
    "    \"\"\"Get daily data from Polygon with caching\"\"\"\n",
    "    cache_dir = get_cache_dir()\n",
    "    cache_file = cache_dir / get_cache_filename(symbol, \"daily\", start_date, end_date)\n",
    "    \n",
    "    # Check if cached data exists and is fresh (less than 1 day old)\n",
    "    if cache_file.exists():\n",
    "        cache_age = (pd.Timestamp.now() - pd.Timestamp.fromtimestamp(cache_file.stat().st_mtime)).days\n",
    "        if cache_age < 1:\n",
    "            print(\"Loading cached daily data...\")\n",
    "            df = pd.read_csv(cache_file, index_col='timestamp', parse_dates=True)\n",
    "            return df\n",
    "    \n",
    "    print(\"Fetching daily data from Polygon...\")\n",
    "    aggs = []\n",
    "    for a in tqdm(client.list_aggs(\n",
    "        ticker=symbol,\n",
    "        multiplier=1,\n",
    "        timespan=\"day\",\n",
    "        from_=start_date,\n",
    "        to=end_date,\n",
    "        limit=50000\n",
    "    ), desc=\"Daily data\"):\n",
    "        aggs.append({\n",
    "            'timestamp': a.timestamp,\n",
    "            'Open': a.open,\n",
    "            'High': a.high,\n",
    "            'Low': a.low,\n",
    "            'Close': a.close,\n",
    "            'Volume': a.volume\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(aggs)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Cache the data\n",
    "    df.to_csv(cache_file)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_atr(daily_data: pd.DataFrame, lookback: int = 14) -> float:\n",
    "    \"\"\"Calculate ATR based on daily data\"\"\"\n",
    "    # Calculate True Range\n",
    "    daily_data = daily_data.copy()\n",
    "    daily_data['High-Low'] = daily_data['High'] - daily_data['Low']\n",
    "    daily_data['High-PrevClose'] = abs(daily_data['High'] - daily_data['Close'].shift(1))\n",
    "    daily_data['Low-PrevClose'] = abs(daily_data['Low'] - daily_data['Close'].shift(1))\n",
    "    daily_data['TR'] = daily_data[['High-Low', 'High-PrevClose', 'Low-PrevClose']].max(axis=1)\n",
    "    \n",
    "    # Calculate ATR\n",
    "    daily_data['ATR'] = daily_data['TR'].rolling(window=lookback).mean()\n",
    "    \n",
    "    return daily_data['ATR'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals(df_1min: pd.DataFrame, min_move_atr_multiple: float = 0.1, atr: float = None) -> pd.DataFrame:\n",
    "    \"\"\"Generate trading signals based on first 5 minutes of market data\"\"\"\n",
    "    df = df_1min.copy()\n",
    "    df['Signal'] = 0\n",
    "    df['Entry_Price'] = np.nan\n",
    "    \n",
    "    # Market open is 9:30 AM ET\n",
    "    market_open_mask = (df.index.hour == 9) & (df.index.minute == 30)\n",
    "    if not any(market_open_mask):\n",
    "        return df\n",
    "        \n",
    "    # Get the market open price\n",
    "    market_open_price = df[market_open_mask]['Open'].iloc[0]\n",
    "    \n",
    "    # Get the 9:34 price\n",
    "    five_min_mask = (df.index.hour == 9) & (df.index.minute == 34)\n",
    "    if not any(five_min_mask):\n",
    "        return df\n",
    "        \n",
    "    five_min_close = df[five_min_mask]['Close'].iloc[0]\n",
    "    \n",
    "    # Calculate the move\n",
    "    price_move = five_min_close - market_open_price\n",
    "    \n",
    "    # Generate signal based on the move\n",
    "    if price_move > 0:  # Long signal\n",
    "        df.loc[df[five_min_mask].index[0], 'Signal'] = 1\n",
    "        df.loc[df[five_min_mask].index[0], 'Entry_Price'] = five_min_close\n",
    "    elif price_move < 0:  # Short signal\n",
    "        df.loc[df[five_min_mask].index[0], 'Signal'] = -1\n",
    "        df.loc[df[five_min_mask].index[0], 'Entry_Price'] = five_min_close\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(symbol: str, start_date: str, end_date: str,\n",
    "                     initial_capital: float,\n",
    "                     stop_atr_multiple: float,\n",
    "                     min_move_atr_multiple: float,\n",
    "                     position_size_risk_pct: float,\n",
    "                     transaction_cost_pct: float,\n",
    "                     max_position_size_pct: float,\n",
    "                     max_leverage: float,\n",
    "                     min_trade_size: float,\n",
    "                     slippage_bps: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run backtest of the strategy with improved position sizing and risk management\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    symbol: str\n",
    "        Trading instrument symbol\n",
    "    start_date: str\n",
    "        Backtest start date\n",
    "    end_date: str\n",
    "        Backtest end date\n",
    "    initial_capital: float\n",
    "        Starting capital\n",
    "    stop_atr_multiple: float\n",
    "        Multiple of ATR for stop loss\n",
    "    min_move_atr_multiple: float\n",
    "        Minimum price move as multiple of ATR\n",
    "    position_size_risk_pct: float\n",
    "        Position size as percentage of capital at risk\n",
    "    transaction_cost_pct: float\n",
    "        Transaction costs as percentage\n",
    "    max_position_size_pct: float\n",
    "        Maximum position size as percentage of capital\n",
    "    max_leverage: float\n",
    "        Maximum allowed leverage\n",
    "    min_trade_size: float\n",
    "        Minimum trade size in dollars\n",
    "    slippage_bps: float\n",
    "        Slippage in basis points\n",
    "    \"\"\"\n",
    "\n",
    "    df_1min, df_5min = get_historical_data(symbol, start_date, end_date)\n",
    "\n",
    "    print(\"Calculating ATR...\")\n",
    "    extended_start = pd.Timestamp(start_date) - pd.Timedelta(days=30)\n",
    "    df_daily = get_daily_data(symbol, extended_start.strftime('%Y-%m-%d'), end_date)\n",
    "\n",
    "    results = []\n",
    "    current_capital = initial_capital\n",
    "\n",
    "    # Make indices timezone-aware\n",
    "    df_1min.index = pd.to_datetime(df_1min.index, utc=True)\n",
    "    df_5min.index = pd.to_datetime(df_5min.index, utc=True)\n",
    "\n",
    "    unique_dates = sorted(set(idx.date() for idx in df_1min.index))\n",
    "    print(f\"Found {len(unique_dates)} trading days to process\")\n",
    "\n",
    "    for day in tqdm(unique_dates, desc=\"Backtest progress\"):\n",
    "        try:\n",
    "            # Calculate ATR\n",
    "            current_date = pd.Timestamp(day)\n",
    "            prev_days = df_daily[df_daily.index < current_date].tail(14)\n",
    "            if len(prev_days) < 14:\n",
    "                continue\n",
    "\n",
    "            atr = calculate_atr(prev_days)\n",
    "            stop_width = atr * stop_atr_multiple\n",
    "\n",
    "            # Get day's data\n",
    "            day_start = pd.Timestamp(day).replace(hour=0, minute=0)\n",
    "            day_end = (day_start + pd.Timedelta(days=1))\n",
    "\n",
    "            day_1min = df_1min[(df_1min.index >= pd.Timestamp(day_start, tz=df_1min.index[0].tz)) &\n",
    "                              (df_1min.index < pd.Timestamp(day_end, tz=df_1min.index[0].tz))]\n",
    "            day_5min = df_5min[(df_5min.index >= pd.Timestamp(day_start, tz=df_5min.index[0].tz)) &\n",
    "                              (df_5min.index < pd.Timestamp(day_end, tz=df_5min.index[0].tz))]\n",
    "\n",
    "            if len(day_1min) == 0 or len(day_5min) == 0:\n",
    "                continue\n",
    "\n",
    "            # Generate signals\n",
    "            signals = generate_signals(day_1min, min_move_atr_multiple, atr)\n",
    "            entry_signals = signals[signals['Signal'] != 0]\n",
    "\n",
    "            if len(entry_signals) == 0:\n",
    "                continue\n",
    "\n",
    "            # Get trade details\n",
    "            entry_time = entry_signals.index[0]\n",
    "            entry_price = entry_signals['Entry_Price'].iloc[0]\n",
    "            trade_direction = entry_signals['Signal'].iloc[0]\n",
    "\n",
    "            # Apply slippage to entry price\n",
    "            entry_price = entry_price * (1 + slippage_bps * np.sign(trade_direction))\n",
    "\n",
    "            # Calculate stop price\n",
    "            stop_price = entry_price - (stop_width * trade_direction)\n",
    "\n",
    "            # Calculate position size based on risk with improved logic\n",
    "            risk_amount = current_capital * position_size_risk_pct\n",
    "            risk_per_share = abs(entry_price - stop_price)\n",
    "            position_size = risk_amount / risk_per_share\n",
    "\n",
    "            # Apply maximum position size constraint\n",
    "            max_position = (current_capital * max_position_size_pct) / entry_price\n",
    "            position_size = min(position_size, max_position)\n",
    "\n",
    "            # Calculate initial trade value\n",
    "            trade_value = position_size * entry_price\n",
    "\n",
    "            # Apply leverage limit\n",
    "            if trade_value > current_capital * max_leverage:\n",
    "                trade_value = current_capital * max_leverage\n",
    "                position_size = trade_value / entry_price\n",
    "\n",
    "            # Check minimum trade size\n",
    "            if trade_value < min_trade_size:\n",
    "                continue\n",
    "\n",
    "            # Apply entry transaction cost\n",
    "            entry_cost = trade_value * transaction_cost_pct\n",
    "            current_capital -= entry_cost\n",
    "\n",
    "            # Track trade through the day using 5-min data\n",
    "            day_data_after_entry = day_5min[day_5min.index > entry_time]\n",
    "\n",
    "            if len(day_data_after_entry) == 0:\n",
    "                continue\n",
    "\n",
    "            # Check for stop hit\n",
    "            stop_hit = False\n",
    "            exit_price = day_data_after_entry['Close'].iloc[-1]  # Default to close at 4 PM\n",
    "\n",
    "            for idx, row in day_data_after_entry.iterrows():\n",
    "                # Check if it's 4 PM\n",
    "                if idx.hour == 16 and idx.minute == 0:\n",
    "                    break\n",
    "\n",
    "                if trade_direction == 1 and row['Low'] <= stop_price:\n",
    "                    stop_hit = True\n",
    "                    exit_price = max(row['Open'], stop_price)  # Realistic fill\n",
    "                    break\n",
    "                elif trade_direction == -1 and row['High'] >= stop_price:\n",
    "                    stop_hit = True\n",
    "                    exit_price = min(row['Open'], stop_price)  # Realistic fill\n",
    "                    break\n",
    "\n",
    "            # Apply slippage to exit price\n",
    "            exit_price = exit_price * (1 - slippage_bps * np.sign(trade_direction))\n",
    "\n",
    "            # Calculate P&L\n",
    "            exit_value = position_size * exit_price\n",
    "            exit_cost = exit_value * transaction_cost_pct\n",
    "            total_transaction_costs = entry_cost + exit_cost\n",
    "\n",
    "            if trade_direction == 1:\n",
    "                pnl = (exit_price - entry_price) * position_size - total_transaction_costs\n",
    "            else:\n",
    "                pnl = (entry_price - exit_price) * position_size - total_transaction_costs\n",
    "\n",
    "            ret = pnl / trade_value\n",
    "            current_capital += pnl\n",
    "\n",
    "            # Ensure capital doesn't go negative\n",
    "            current_capital = max(0, current_capital)\n",
    "\n",
    "            results.append({\n",
    "                'Date': day,\n",
    "                'Direction': trade_direction,\n",
    "                'Entry_Time': entry_time,\n",
    "                'Entry_Price': entry_price,\n",
    "                'Stop_Price': stop_price,\n",
    "                'Exit_Price': exit_price,\n",
    "                'Position_Size': position_size,\n",
    "                'Trade_Value': trade_value,\n",
    "                'Stop_Hit': stop_hit,\n",
    "                'ATR': atr,\n",
    "                'Stop_Width': stop_width,\n",
    "                'PnL': pnl,\n",
    "                'Return': ret,\n",
    "                'Capital': current_capital,\n",
    "                'Transaction_Costs': total_transaction_costs\n",
    "            })\n",
    "\n",
    "            # Break if capital is depleted\n",
    "            if current_capital <= min_trade_size:\n",
    "                print(f\"Trading stopped due to insufficient capital on {day}\")\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {day}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    if len(results_df) > 0:\n",
    "        results_df.set_index('Date', inplace=True)\n",
    "        print(f\"Successfully processed {len(results_df)} trades\")\n",
    "    else:\n",
    "        print(\"No trades were generated during the backtest period\")\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(results: pd.DataFrame, initial_capital: float = 100000.0) -> None:\n",
    "    \"\"\"\n",
    "    Analyze and display backtest results with comprehensive performance metrics\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    results: pd.DataFrame\n",
    "        DataFrame containing backtest results\n",
    "    initial_capital: float\n",
    "        Initial capital used in backtest\n",
    "    \"\"\"\n",
    "    if len(results) == 0:\n",
    "        print(\"No trades were executed in the backtest period\")\n",
    "        return\n",
    "\n",
    "    # Ensure index is datetime\n",
    "    if not isinstance(results.index, pd.DatetimeIndex):\n",
    "        results.index = pd.to_datetime(results.index)\n",
    "\n",
    "    # Calculate daily returns and equity curve\n",
    "    results['Cumulative_Return'] = (1 + results['Return']).cumprod()\n",
    "    results['Equity_Curve'] = initial_capital * results['Cumulative_Return']\n",
    "\n",
    "    # Calculate drawdown series\n",
    "    results['Peak'] = results['Equity_Curve'].expanding().max()\n",
    "    results['Drawdown'] = (results['Equity_Curve'] - results['Peak']) / results['Peak']\n",
    "\n",
    "    # Trade Statistics\n",
    "    total_trades = len(results)\n",
    "    winning_trades = len(results[results['PnL'] > 0])\n",
    "    losing_trades = len(results[results['PnL'] <= 0])\n",
    "    win_rate = winning_trades / total_trades if total_trades > 0 else 0\n",
    "\n",
    "    # Position and Capital Statistics\n",
    "    avg_position_size = results['Position_Size'].mean()\n",
    "    avg_trade_value = results['Trade_Value'].mean()\n",
    "    avg_capital_usage = (results['Trade_Value'] / results['Capital'].shift(1)).mean()\n",
    "\n",
    "    # P&L Statistics\n",
    "    total_pnl = results['PnL'].sum()\n",
    "    total_costs = results['Transaction_Costs'].sum()\n",
    "    net_pnl = total_pnl - total_costs\n",
    "\n",
    "    # Average win/loss\n",
    "    avg_win = results[results['PnL'] > 0]['PnL'].mean()\n",
    "    avg_loss = results[results['PnL'] <= 0]['PnL'].mean()\n",
    "    max_win = results['PnL'].max()\n",
    "    max_loss = results['PnL'].min()\n",
    "\n",
    "    # Risk/Reward Metrics\n",
    "    profit_factor = abs(results[results['PnL'] > 0]['PnL'].sum() /\n",
    "                       results[results['PnL'] < 0]['PnL'].sum()) if losing_trades > 0 else float('inf')\n",
    "\n",
    "    # Stop Analysis\n",
    "    stops_hit = len(results[results['Stop_Hit'] == True])\n",
    "    stop_rate = stops_hit / total_trades if total_trades > 0 else 0\n",
    "\n",
    "    # Use the Capital column directly instead of calculating it\n",
    "    results['Return'] = results['Capital'].pct_change()  # Calculate returns from actual capital changes\n",
    "    results['Cumulative_Return'] = results['Capital'] / initial_capital - 1  # Calculate cumulative return directly\n",
    "    \n",
    "    # Portfolio Performance calculations\n",
    "    final_capital = results['Capital'].iloc[-1]  # Use actual final capital\n",
    "    total_return = (final_capital - initial_capital) / initial_capital\n",
    "\n",
    "    # Risk Metrics\n",
    "    max_drawdown = results['Drawdown'].min() * 100\n",
    "    avg_drawdown = results['Drawdown'].mean() * 100\n",
    "\n",
    "    # Calculate daily returns for ratios\n",
    "    daily_returns = results['Return'].resample('D').sum().fillna(0)\n",
    "    risk_free_rate = 0.02  # Assuming 2% risk-free rate\n",
    "    excess_returns = daily_returns - risk_free_rate/252\n",
    "\n",
    "    # Risk Ratios\n",
    "    # Calculate annualized return using actual trading days\n",
    "    years = (results.index[-1] - results.index[0]).days / 365.25\n",
    "    annualized_return = ((1 + total_return) ** (1/years) - 1) * 100\n",
    "    annualized_volatility = daily_returns.std() * np.sqrt(252) * 100\n",
    "    sharpe_ratio = np.sqrt(252) * excess_returns.mean() / daily_returns.std() if daily_returns.std() != 0 else 0\n",
    "    sortino_ratio = np.sqrt(252) * excess_returns.mean() / daily_returns[daily_returns < 0].std() if len(daily_returns[daily_returns < 0]) > 0 else 0\n",
    "    calmar_ratio = -annualized_return / max_drawdown if max_drawdown != 0 else 0\n",
    "\n",
    "    # Maximum Consecutive Wins/Losses\n",
    "    consecutive_wins = consecutive_losses = 0\n",
    "    max_consecutive_wins = max_consecutive_losses = 0\n",
    "\n",
    "    for pnl in results['PnL']:\n",
    "        if pnl > 0:\n",
    "            consecutive_wins += 1\n",
    "            consecutive_losses = 0\n",
    "            max_consecutive_wins = max(max_consecutive_wins, consecutive_wins)\n",
    "        else:\n",
    "            consecutive_losses += 1\n",
    "            consecutive_wins = 0\n",
    "            max_consecutive_losses = max(max_consecutive_losses, consecutive_losses)\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Strategy Performance Analysis\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"\\nBacktest Period: {results.index[0].strftime('%Y-%m-%d')} to {results.index[-1].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    print(f\"\\n{'Trade Statistics':=^40}\")\n",
    "    print(f\"Total Trades: {total_trades:,}\")\n",
    "    print(f\"Win Rate: {win_rate:.2%}\")\n",
    "    print(f\"Profit Factor: {profit_factor:.2f}\")\n",
    "    print(f\"Average Position Size: ${avg_position_size:,.2f}\")\n",
    "    print(f\"Average Trade Value: ${avg_trade_value:,.2f}\")\n",
    "    print(f\"Average Capital Usage: {avg_capital_usage:.2%}\")\n",
    "    print(f\"Total Transaction Costs: ${total_costs:,.2f}\")\n",
    "    print(f\"Stop-Loss Hit Rate: {stop_rate:.2%}\")\n",
    "\n",
    "    print(f\"\\n{'P&L Statistics':=^40}\")\n",
    "    print(f\"Net P&L: ${net_pnl:,.2f}\")\n",
    "    print(f\"Average Win: ${avg_win:,.2f}\")\n",
    "    print(f\"Average Loss: ${avg_loss:,.2f}\")\n",
    "    print(f\"Largest Win: ${max_win:,.2f}\")\n",
    "    print(f\"Largest Loss: ${max_loss:,.2f}\")\n",
    "    print(f\"Max Consecutive Wins: {max_consecutive_wins}\")\n",
    "    print(f\"Max Consecutive Losses: {max_consecutive_losses}\")\n",
    "\n",
    "    print(f\"\\n{'Portfolio Performance':=^40}\")\n",
    "    print(f\"Initial Capital: ${initial_capital:,.2f}\")\n",
    "    print(f\"Final Capital: ${final_capital:,.2f}\")\n",
    "    print(f\"Total Return: {total_return:.2%}\")\n",
    "    print(f\"Annualized Return: {annualized_return:.2f}%\")\n",
    "    print(f\"Annualized Volatility: {annualized_volatility:.2f}%\")\n",
    "\n",
    "    print(f\"\\n{'Risk Metrics':=^40}\")\n",
    "    print(f\"Maximum Drawdown: {max_drawdown:.2f}%\")\n",
    "    print(f\"Average Drawdown: {avg_drawdown:.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "    print(f\"Sortino Ratio: {sortino_ratio:.2f}\")\n",
    "    print(f\"Calmar Ratio: {calmar_ratio:.2f}\")\n",
    "\n",
    "    # Plotting\n",
    "    # Use a basic matplotlib style instead of seaborn\n",
    "    plt.style.use('default')\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(15, 20))\n",
    "\n",
    "    # Equity Curve with Drawdown\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(results.index, results['Equity_Curve'], label='Equity Curve', color='blue')\n",
    "    ax1.set_title('Equity Curve')\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Portfolio Value ($)')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(loc='upper left')\n",
    "\n",
    "    # Drawdown plot on twin axis\n",
    "    ax1_dd = ax1.twinx()\n",
    "    ax1_dd.fill_between(results.index, 0, results['Drawdown'] * 100,\n",
    "                       color='red', alpha=0.3, label='Drawdown %')\n",
    "    ax1_dd.set_ylabel('Drawdown %')\n",
    "    ax1_dd.legend(loc='upper right')\n",
    "\n",
    "    # Trade Values Over Time\n",
    "    axes[1].plot(results.index, results['Trade_Value'], color='green')\n",
    "    axes[1].set_title('Trade Values Over Time')\n",
    "    axes[1].set_xlabel('Date')\n",
    "    axes[1].set_ylabel('Trade Value ($)')\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Monthly returns\n",
    "    monthly_returns = results['Return'].resample('M').sum()\n",
    "    axes[2].bar(monthly_returns.index, monthly_returns,\n",
    "                color=['green' if x >= 0 else 'red' for x in monthly_returns])\n",
    "    axes[2].set_title('Monthly Returns')\n",
    "    axes[2].set_xlabel('Month')\n",
    "    axes[2].set_ylabel('Return')\n",
    "    axes[2].grid(True)\n",
    "    plt.setp(axes[2].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    # Distribution of returns\n",
    "    axes[3].hist(results['Return'], bins=50, density=True, alpha=0.5, color='blue')\n",
    "    axes[3].set_title('Distribution of Returns')\n",
    "    axes[3].set_xlabel('Return')\n",
    "    axes[3].set_ylabel('Frequency')\n",
    "    axes[3].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Additional rolling metrics plot\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 15))\n",
    "\n",
    "    # Rolling Sharpe Ratio (252-day)\n",
    "    rolling_sharpe = np.sqrt(252) * results['Return'].rolling(252).mean() / results['Return'].rolling(252).std()\n",
    "    axes[0].plot(rolling_sharpe.index, rolling_sharpe)\n",
    "    axes[0].set_title('Rolling 252-day Sharpe Ratio')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Rolling 63-day (quarter) Win Rate\n",
    "    rolling_winrate = results['PnL'].rolling(63).apply(lambda x: np.sum(x > 0) / len(x))\n",
    "    axes[1].plot(rolling_winrate.index, rolling_winrate)\n",
    "    axes[1].set_title('Rolling 63-day Win Rate')\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Rolling 21-day Average Trade Value\n",
    "    rolling_trade_value = results['Trade_Value'].rolling(21).mean()\n",
    "    axes[2].plot(rolling_trade_value.index, rolling_trade_value)\n",
    "    axes[2].set_title('Rolling 21-day Average Trade Value')\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'total_trades': total_trades,\n",
    "        'win_rate': win_rate,\n",
    "        'profit_factor': profit_factor,\n",
    "        'net_pnl': net_pnl,\n",
    "        'total_return': total_return,\n",
    "        'annualized_return': annualized_return,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'sortino_ratio': sortino_ratio,\n",
    "        'calmar_ratio': calmar_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = backtest_strategy(\n",
    "    symbol='TQQQ',\n",
    "    start_date='2020-01-01',\n",
    "    end_date='2025-02-26',\n",
    "    initial_capital=100000,\n",
    "    stop_atr_multiple=0.075,\n",
    "    min_move_atr_multiple=0.1,\n",
    "    position_size_risk_pct=0.02,  # 2% risk per trade\n",
    "    transaction_cost_pct=0,   # commission free trading of TQQQ with tastytrade\n",
    "    max_position_size_pct=0.25,   # max 25% of capital per trade\n",
    "    max_leverage=1.0,            # no leverage\n",
    "    min_trade_size=1000,         # minimum $1000 per trade\n",
    "    slippage_bps=0        # 0 bps slippage\n",
    ")\n",
    "\n",
    "analyze_results(results, initial_capital=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqqq_d1_intraday",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
